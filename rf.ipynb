{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [],
   "source": [
    "from IPython.display import display\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Random Forests\n",
    "\n",
    "Spencer Boucher\n",
    "\n",
    "[Source Code](https://github.com/justmytwospence/random-forests-lesson)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Leaning Objectives\n",
    "\n",
    "- Why random forests?\n",
    "- Review of decision trees (especially spitting criteria)\n",
    "- Bagging\n",
    "- The random subspace method\n",
    "- Tuning hyperparameters\n",
    "- Variable importance"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Why random Forests?\n",
    "\n",
    "- Modern: developed in the 1990s by [Tin Kam Ho](http://www.machine-learning.martinsewell.com/ensembles/rsm/Ho1998.pdf), [Leo Breiman, and Adele Cutler](http://machinelearning202.pbworks.com/w/file/fetch/60606349/breiman_randomforests.pdf)\n",
    "- Works well for *both* **regression** *and* **classification**\n",
    "- Handles **categorical** features, **numeric** features, and **missing data** well\n",
    "- Has many convenient and efficient implementations, including `sklearn`\n",
    "- Requires relatively little tuning\n",
    "- Highly parallelizable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PassengerId</th>\n",
       "      <th>Survived</th>\n",
       "      <th>Pclass</th>\n",
       "      <th>Name</th>\n",
       "      <th>Sex</th>\n",
       "      <th>Age</th>\n",
       "      <th>SibSp</th>\n",
       "      <th>Parch</th>\n",
       "      <th>Ticket</th>\n",
       "      <th>Fare</th>\n",
       "      <th>Cabin</th>\n",
       "      <th>Embarked</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>108</td>\n",
       "      <td>1</td>\n",
       "      <td>28</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>523</td>\n",
       "      <td>18</td>\n",
       "      <td>146</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>190</td>\n",
       "      <td>0</td>\n",
       "      <td>51</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>596</td>\n",
       "      <td>207</td>\n",
       "      <td>81</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>353</td>\n",
       "      <td>0</td>\n",
       "      <td>34</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>669</td>\n",
       "      <td>41</td>\n",
       "      <td>146</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>272</td>\n",
       "      <td>0</td>\n",
       "      <td>47</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>49</td>\n",
       "      <td>189</td>\n",
       "      <td>55</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>15</td>\n",
       "      <td>1</td>\n",
       "      <td>47</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>472</td>\n",
       "      <td>43</td>\n",
       "      <td>146</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   PassengerId  Survived  Pclass  Name  Sex  Age  SibSp  Parch  Ticket  Fare  Cabin  Embarked\n",
       "0            0         0       2   108    1   28      1      0     523    18    146         3\n",
       "1            1         1       0   190    0   51      1      0     596   207     81         0\n",
       "2            2         1       2   353    0   34      0      0     669    41    146         3\n",
       "3            3         1       0   272    0   47      1      0      49   189     55         3\n",
       "4            4         0       2    15    1   47      0      0     472    43    146         3"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "le = LabelEncoder()\n",
    "\n",
    "titanic_data = pd.read_csv(\"data/titanic.csv\")\n",
    "titanic_data = titanic_data.fillna({\"Cabin\":\"NA\", \"Embarked\": \"NA\"}).apply(le.fit_transform)\n",
    "display(titanic_data.head())\n",
    "survived = titanic_data.pop(\"Survived\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Decision Trees"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "![classification-tree](images/classification-tree.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "![regression-tree](images/regression-tree.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Splitting Criteria\n",
    "\n",
    "- Regression\n",
    "  - MSE\n",
    "- Classificatoin\n",
    "  - misclassication error\n",
    "  - entropy\n",
    "  - Gini index"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Misclassification error\n",
    "\n",
    "- Not continuously differentiable\n",
    "- Ends up not being as sensitive as we would like in practice"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Entropy (information gain)\n",
    "\n",
    "$$\\textit{Entropy}: H(E) = -\\sum_{j=1}^{c}p_j\\log p_j$$\n",
    "\n",
    "- information gain is the entropy of the parent node minus the entropy of the child nodes\n",
    "- from information theory\n",
    "- continuously differentiable\n",
    "- favors pure nodes even in situations with equal misclassification rate\n",
    "- requires taking a logarithm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Gini\n",
    "$$\\textit{Gini}: \\mathit{Gini}(E) = 1 - \\sum_{j=1}^{c}p_j^2$$\n",
    "\n",
    "- from statistics\n",
    "- related to the Gini Coefficient for measuring wealth inequality\n",
    "- computationally simple (no logarithm)\n",
    "- also continuously differentiable\n",
    "- also favors pure nodes more than classification error does"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Which should you use?\n",
    "\n",
    "![gini-vs-entropy](images/gini-vs-entropy.png)\n",
    "\n",
    "- Use Gini if you are sticking with just one\n",
    "- Or: treat it as hyperparameter"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## The bias variance tradeoff\n",
    "\n",
    "![bias-variance](images/bias-variance.png)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "How have we seen the high variance of trees handled before? (hint: involved a parameter $\\alpha$)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "Cost-complexity pruning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## **B**ootstrap **AGG**regat**ING**\n",
    "\n",
    "- We can train *many* trees on bootstrapped samples\n",
    "- Every tree will have the same bias, but by combining their estimates, we reduce overall variance\n",
    "- Classification: every individual tree \"votes\" on the class or \n",
    "- Regression: average each tree\n",
    "\n",
    "![bias-variance](images/bias-variance.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Any given observation will only be used to fit $1 - \\frac{1}{e}$ of the trees in the forest ($63\\%$)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "abcdefghijklmnopqrstuvwxyz -> unique letters:  26\n",
      "wwupwqbwhrofclwhslnpzuttqu -> unique letters:  15\n",
      "Proportion of letters in sample: 57.7%\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from string import ascii_lowercase\n",
    "\n",
    "print(ascii_lowercase, \n",
    "      \"-> unique letters: \",\n",
    "      len(ascii_lowercase))\n",
    "sample = np.random.choice(list(ascii_lowercase),  \n",
    "                          len(ascii_lowercase),\n",
    "                          replace=True)\n",
    "print(''.join(sample), \n",
    "      \"-> unique letters: \",\n",
    "      len(set(sample)))\n",
    "\n",
    "print('Proportion of letters in sample: {:.1%}'.format(len(set(sample))/len(sample)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Out-of-bag error estimates\n",
    "\n",
    "- We can average or vote with the remaining $37\\%$ of trees to make a prediction for each observation.\n",
    "- This is called the out-of-bag error (OOB).\n",
    "- For sufficiently large forest size, OOB error approaches LOO error.\n",
    "\n",
    "![images](images/oob-vs-test-error.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Random subspace method\n",
    "\n",
    "- Bagging suffers from the problem that trees tend to be very similar to one another\n",
    "- We can *decorrelate* trees in the forest by bagging the *features* as well\n",
    "- Wisdom of the crowds analogy redux\n",
    "- Every time we consider a split, limit our choices to $m$ of the $p$ variables in the dataset\n",
    "- $m$ is often defaulted to $\\sqrt(p)$, but can reasonbly be as low as $1$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "![m-vs-p](images/m-vs-p.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": false,
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
       "            max_depth=None, max_features='sqrt', max_leaf_nodes=None,\n",
       "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "            min_samples_leaf=1, min_samples_split=2,\n",
       "            min_weight_fraction_leaf=0.0, n_estimators=1000, n_jobs=-1,\n",
       "            oob_score=True, random_state=None, verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "forest = RandomForestClassifier(n_estimators=1000, \n",
    "                                criterion='gini',\n",
    "                                max_features='sqrt',\n",
    "                                bootstrap=True,\n",
    "                                oob_score=True,\n",
    "                                n_jobs=-1)\n",
    "forest.fit(titanic_data, survived)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Hyperparameters\n",
    "\n",
    "- `criterion`\n",
    "- `max_depth`: maximum depth of an individual tree\n",
    "- `min_samples_split`: minimum number of samples required to split\n",
    "- `min_samples_leaf`: minimum number of samples required to be at a leaf node\n",
    "- `min_impurity_decrease`: minimum impurity decrease that can cause a split\n",
    "- [Visual demo widget](https://cs.stanford.edu/%7Ekarpathy/svmjs/demo/demoforest.html)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Grid Search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=None, error_score='raise',\n",
       "       estimator=RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
       "            max_depth=None, max_features='auto', max_leaf_nodes=None,\n",
       "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "            min_samples_leaf=1, min_samples_split=2,\n",
       "            min_weight_fraction_leaf=0.0, n_estimators=100, n_jobs=1,\n",
       "            oob_score=False, random_state=None, verbose=0,\n",
       "            warm_start=False),\n",
       "       fit_params=None, iid=True, n_jobs=1,\n",
       "       param_grid={'max_depth': [3, None], 'max_features': [1, 10, 'sqrt', 'log2'], 'min_samples_split': [2, 3, 10], 'min_samples_leaf': [1, 3, 10], 'criterion': ['gini', 'entropy']},\n",
       "       pre_dispatch='2*n_jobs', refit=True, return_train_score='warn',\n",
       "       scoring=None, verbose=0)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "clf = RandomForestClassifier(n_estimators=100)\n",
    "\n",
    "# use a full grid over all parameters\n",
    "param_grid = {\"max_depth\": [3, None],\n",
    "              \"max_features\": [1, 10, 'sqrt', 'log2'],\n",
    "              \"min_samples_split\": [2, 3, 10],\n",
    "              \"min_samples_leaf\": [1, 3, 10],\n",
    "              \"criterion\": [\"gini\", \"entropy\"]}\n",
    "\n",
    "# run grid search\n",
    "grid_search = GridSearchCV(clf, param_grid=param_grid)\n",
    "grid_search.fit(titanic_data, survived)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Variable Importance\n",
    "\n",
    "Two methods:\n",
    "\n",
    "1. Mean impurity decrease: Add up the decreases in Gini index across every tree when a given variable is used for a split. The units on this meassure for a particular feature are meaningless. They are only interesting relative to each other.\n",
    "\n",
    "2. Mean accuracy decrease: Measure the decrease in accuracy on OOB data when values of each feature are randomly permuted (effectively annihilating it's signal)\n",
    "\n",
    "The `feature_importances_` attribute in `sklearn` uses method #1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.23693219, 0.13305347, 0.11576553, 0.1134657 , 0.10969246,\n",
       "       0.10099355, 0.06035738, 0.05939177, 0.02786738, 0.02337968,\n",
       "       0.0191009 ])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "importances[indices]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x1128a78d0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "importances = forest.feature_importances_\n",
    "std = np.std([tree.feature_importances_ for tree in forest.estimators_], axis=0)\n",
    "indices = np.argsort(importances)[::-1]\n",
    "plt.figure(figsize=(16,8)); plt.title(\"Feature importances\"); plt.ylabel(\"Mean decrease in Gini\")\n",
    "plt.bar(titanic_data.columns[indices], importances[indices], yerr=std[indices])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Disadvantages\n",
    "\n",
    "- Can give wonky results on data that falls outside the range of the training data\n",
    "- Less interpretable than many models\n",
    "- Relatively slow at prediction time"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Summary\n",
    "\n",
    "- Random forests reduce the variance of a single decision tree\n",
    "  - Bootstrap sampling the data\n",
    "  - Random feature subspace\n",
    "- Error can be computed (\"for free\") on the out-of-bag observations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Appendix"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Evaluating Performance \n",
    "\n",
    "The output of a random forest *classifier* is actually a proportion.\n",
    "\n",
    "This means that we don't have to limit ourselves to a hard classification according to the majority; we can do some other interesting things"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## ROC curves\n",
    "\n",
    "One thing we can do is calibrate our predictions according to how aggressive or conservative we want to be.\n",
    "\n",
    "![roc-curve](images/roc-curve.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## log-loss\n",
    "\n",
    "![log-loss](images/log-loss.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Trees vs linear models\n",
    "\n",
    "![tree-vs-linear](images/tree-vs-linear.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Bagging vs Boosting\n",
    "\n",
    "![rf-bagging-boosting](images/rf-bagging-boosting.png)"
   ]
  }
 ],
 "metadata": {
  "celltoolbar": "Slideshow",
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
